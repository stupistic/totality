{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data_list  = []\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(r'custom path'):# add the desire input path\n",
    "    for filename in filenames:\n",
    "        data_list.append (os.path.join(dirname, filename))\n",
    "\n",
    "#using the data file we have set the path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(r'custom path')\n",
    "labels.head()\n",
    "#csv file containing basic infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def barw(ax): \n",
    "    \n",
    "    for p in ax.patches:\n",
    "        val = p.get_width()\n",
    "        x = p.get_x()+ p.get_width()\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax.annotate(round(val,2),(x,y))\n",
    "\n",
    "plt.figure(figsize = (15,30))\n",
    "ax0 =sns.countplot(y=labels['breed'],order=labels['breed'].value_counts().index)\n",
    "barw(ax0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=['Bombay', 'Calico', 'Burmese', 'Himalayan',\n",
    "'Munchkin', 'Ragdoll', 'Siberian', 'British Shorthair', 'Russian Blue', \n",
    "                 'Dilute Calico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= []\n",
    "final_labels = []\n",
    "\n",
    "for path in data_list:\n",
    "    label = path.split(os.path.sep)[-2]\n",
    "    if label in test_labels:\n",
    "\n",
    "        filename.append(path)\n",
    "        final_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict.fromkeys(final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_labels),len(filename)#labels are now set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=pd.DataFrame(list(zip(filename, final_labels) ), columns = ['path', 'Labels'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(nrows=2, ncols=2,figsize=(10,20),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(a.flat):\n",
    "    ax.imshow(plt.imread(grid.path[i]))\n",
    "    ax.set_title(grid.Labels[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITING THE DATA WITH 80/20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = .80\n",
    "valid_ratio = 0.10     \n",
    "testing = 0.20\n",
    "\n",
    "train, test = train_test_split(grid, test_size = testing )\n",
    "val, test = train_test_split(test, test_size=testing/(testing + valid_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generate = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.2,height_shift_range=0.2,horizontal_flip = 'true')\n",
    "   \n",
    "\n",
    "x_train =  data_generate.flow_from_dataframe(dataframe = train,  x_col='path', y_col='Labels',  target_size=(299, 299), shuffle=False, batch_size=10, seed=10)\n",
    "x_val = data_generate.flow_from_dataframe(dataframe = val,  x_col='path', y_col='Labels',  target_size=(299, 299), shuffle=False, batch_size=10, seed=10)\n",
    "x_test = data_generate.flow_from_dataframe(dataframe = test,  x_col='path', y_col='Labels',  target_size=(299, 299), shuffle=False, batch_size=10, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING INCEPTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalmodel= InceptionV3(weights= 'imagenet', include_top=False, input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finalmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(finalmodel)\n",
    "cnn.add(GlobalAveragePooling2D())\n",
    "cnn.add(Dense(128))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(10, activation = 'relu'))\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cnn.compile(optimizer= \"adam\", loss='mse', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "history = cnn.fit(x_train, validation_data = x_val,steps_per_epoch = 175,validation_steps = 44,\n",
    "                epochs = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = cnn.predict(x_test)\n",
    "predic = np.argmax(predictions, axis=1)\n",
    "predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = x_train.class_indices\n",
    "final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Labels\"].replace({\"Bombay\": 0,'British Shorthair': 1,\n",
    " 'Burmese': 2,\n",
    " 'Calico': 3,\n",
    " 'Dilute Calico': 4,\n",
    " 'Himalayan': 5,\n",
    " 'Munchkin': 6,\n",
    " 'Ragdoll': 7,\n",
    " 'Russian Blue': 8,\n",
    " 'Siberian': 9}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = cnn.evaluate(x_test)[1] * 100\n",
    "print('accuracy: ',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test.Labels , predic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_percent =cnn.predict_proba(x_test)\n",
    "predic_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('score',f1_score(test.Labels, predic, average = 'weighted') *100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
